{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "%pip install requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/timchen2/Desktop/Knowledge-Graph-Chat-demo/venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "from string import Template\n",
    "import json\n",
    "from neo4j import GraphDatabase\n",
    "import glob # search for files that match a specific file pattern or name\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "from dotenv import load_dotenv\n",
    "from time import sleep\n",
    "import requests\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load env variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neo4j configuration & constraints\n",
    "neo4j_url = os.getenv(\"NEO4J_URI\")\n",
    "neo4j_user = os.getenv(\"NEO4J_USERNAME\")\n",
    "neo4j_password = os.getenv(\"NEO4J_PASSWORD\")\n",
    "gds = GraphDatabase.driver(neo4j_url, auth=(neo4j_user, neo4j_password))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Helper Function Outline\n",
    "\n",
    "##### Flow : LLM process unstructured data into entities&relationship -> Generate Cypher to construct Knowledge Graph\n",
    "\n",
    "#### LLM model\n",
    "- ##### Function to call the OpenAI API (better performance but need $$)\n",
    "    - def process_gpt(optional)\n",
    "- ##### Function to call the Ollama API (Opensource free LLM model can be installed on Local as REST API)\n",
    "    - def process_ollama(file_prompt, system_msg)\n",
    "\n",
    "##### Function to pre-process unstructureed data in order to return JSON-object of all the entities and relationships for building Knowledge Graph\n",
    "- def extract_entities_relationships(folder, prompt_template)\n",
    "\n",
    "##### Function to take JSON-object of entities and relationships and generate cypher query for creating those entities\n",
    "- def generate_cypher(json_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ollama(file_prompt, system_msg):\n",
    "    # Combine system message and user prompt\n",
    "    combined_prompt = f\"{system_msg}\\n\\nHuman: {file_prompt}\\n\\n Assistant:\"\n",
    "    \n",
    "    # Ollama API endpoint\n",
    "    url =\"http://localhost:11434/api/generate\"\n",
    "    payload = {\n",
    "        \"model\": \"mistral-custom\",\n",
    "        \"prompt\": combined_prompt,\n",
    "        \"stream\": False\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, json=payload)\n",
    "        response.raise_for_status() # Raise an HTTPError for bad responses\n",
    "\n",
    "        result = response.json()\n",
    "        nlp_results = result['response']\n",
    "    except requests.RequestException as e:\n",
    "        nlp_results = f\"Error: {str(e)}\"\n",
    "    \n",
    "    sleep(8) # Sleep for 8 seconds to avoid overloading the server - Rate Limiting\n",
    "    return nlp_results\n",
    "\n",
    "def fix_json(raw_json):\n",
    "    # Remove all comments (both single-line and multi-line)\n",
    "    raw_json = re.sub(r'//.*?$|/\\*.*?\\*/|\\'(?:\\\\.|[^\\\\\\'])*\\'|\"(?:\\\\.|[^\\\\\"])*\"', \n",
    "                      lambda m: '' if m.group(0).startswith('/') else m.group(0), \n",
    "                      raw_json, flags=re.DOTALL | re.MULTILINE)\n",
    "    \n",
    "    # Replace unescaped apostrophes with escaped ones, but only within string values\n",
    "    raw_json = re.sub(r'(?<!\\\\)\"(.*?)(?<!\\\\)\"', lambda m: '\"{}\"'.format(m.group(1).replace(\"'\", \"\\\\'\")), raw_json)\n",
    "    \n",
    "    # Replace single quotes with double quotes\n",
    "    raw_json = raw_json.replace(\"'\", '\"')\n",
    "    \n",
    "    # Replace None with null\n",
    "    raw_json = raw_json.replace(\"None\", \"null\")\n",
    "    \n",
    "    # Remove trailing commas in arrays and objects\n",
    "    raw_json = re.sub(r',\\s*}', '}', raw_json)\n",
    "    raw_json = re.sub(r',\\s*]', ']', raw_json)\n",
    "    \n",
    "    # Remove any remaining whitespace at the end of the JSON\n",
    "    raw_json = raw_json.strip()\n",
    "    \n",
    "    try:\n",
    "        # Try to parse the fixed JSON\n",
    "        return json.loads(raw_json)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON decoding error after fixing: {e}\")\n",
    "        print(\"Partially fixed JSON:\")\n",
    "        print(raw_json)\n",
    "        \n",
    "        # If it still fails, try to extract valid JSON using regex\n",
    "        match = re.search(r'\\{.*\\}', raw_json, re.DOTALL)\n",
    "        if match:\n",
    "            try:\n",
    "                return json.loads(match.group(0))\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Failed to extract valid JSON: {e}\")\n",
    "                return None\n",
    "        return None\n",
    "\n",
    "def extract_entities_relationships(folder, prompt_template):\n",
    "    start = timer()\n",
    "    files = glob.glob(f\"./data/{folder}/*\")\n",
    "\n",
    "    system_msg = \"You are a helpful IT-project and account management expert who is extremely skillful to extract information from documents and always return VALID JSON. YOU ALWAY RETURN VALID JSON\"\n",
    "    \n",
    "    print(f\"Running pipeline for {len(files)} files in {folder} folder.\")\n",
    "\n",
    "    results = []\n",
    "    for i, file in enumerate(files):\n",
    "        print(f\"\\nProcessing file {i+1}/{len(files)}: {file} .\")\n",
    "        try:\n",
    "            with open(file, 'r', encoding='utf-8') as f:\n",
    "                # Read the file and remove any trailing whitespaces\n",
    "                text = f.read().strip()\n",
    "                # Replace the template with the actual text\n",
    "                prompt = Template(prompt_template).substitute(ctext=text)\n",
    "                result = process_ollama(prompt, system_msg = system_msg)\n",
    "                \n",
    "                # edge case for empty response\n",
    "                if not result.strip():\n",
    "                    print(f\"Warning🌝: Empty response for file {file}\")\n",
    "                    continue\n",
    "                \n",
    "                # more tracker to track the progress\n",
    "                print(\"Attemping to parse JSON...\")\n",
    "                try:\n",
    "                    parsed_result = json.loads(result)\n",
    "                    results.append(parsed_result)\n",
    "                    print(\"JSON parsed successfully\")\n",
    "                \n",
    "                except json.JSONDecodeError as json_err:\n",
    "                    print(f\"JSON parsing error: {json_err}\")\n",
    "                    print(\"Full raw result:\")\n",
    "                    print(result)\n",
    "                    print(\"\\nAttempting to fix JSON...\")\n",
    "                    fixed_result = fix_json(result)\n",
    "                    if fixed_result:\n",
    "                        results.append(parsed_result)\n",
    "                        print(\"Fixed JSON successfully\")\n",
    "                    else:\n",
    "                        print(\"Failed to fix JSON\")\n",
    "                        print(\"Full raw result:\")\n",
    "                        print(fixed_result)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file} : {str(e)}\")\n",
    "    \n",
    "    end = timer()\n",
    "    print(f\"\\nPipeline completed in {end-start} seconds\")\n",
    "    return results\n",
    "# Function to take JSON-object of entities and relationships. Generate valid cypher statements(entities&relationship) in order to load them into Neo4j database.\n",
    "def generate_cypher(json_obj):\n",
    "    en_statements = []\n",
    "    rel_statements = []\n",
    "\n",
    "    en_label_dict = {}\n",
    "\n",
    "    # \n",
    "    for i, obj in enumerate(json_obj):\n",
    "        print(f\"Generating Cypher for file {i + 1} of {len(json_obj)}\")\n",
    "\n",
    "        # Loop through entities and create cypher statements for each entity(node)\n",
    "        for entity in obj['entities']:\n",
    "            label = entity['label']\n",
    "            id = entity['id']\n",
    "            id = id.replace(\"-\", \"\").replace(\"_\", \"\")\n",
    "            # only extract properties that are not lable or id\n",
    "            properties = {k: v for k, v in entity.items() if k not in ['label', 'id']}\n",
    "\n",
    "            # MERGE - create if not exist, if exist, it will update\n",
    "            # The reason why don't use CREATE is to avoid creating duplicate nodes\n",
    "            cypher = f'MERGE (n:{label} {{id: \"{id}\" }})'\n",
    "            if properties:\n",
    "                props_str = \", \".join(\n",
    "                    [f'n.{key} = \"{value}\"' for key, value in properties.items()]\n",
    "                )\n",
    "                cypher += f\" ON CREATE SET {props_str}\"\n",
    "            \n",
    "            en_statements.append(cypher)\n",
    "            # This is entity for relationship - key=id: value=label\n",
    "            en_label_dict[id] = label\n",
    "\n",
    "        # Loop through relationships and create cypher statements by merging the ndoes and creating the relationships\n",
    "        for rel in obj[\"relationships\"]:\n",
    "            source_id, rel_type, target_id = rel.split('|')\n",
    "            source_id = source_id.replace(\"-\", \"\").replace(\"_\", \"\")\n",
    "            target_id = target_id.replace(\"-\", \"\").replace(\"_\", \"\")\n",
    "\n",
    "            # test to find whether the entities are in the en_label_dict\n",
    "            try:\n",
    "                source_label = en_label_dict[source_id]\n",
    "                target_label = en_label_dict[target_id]\n",
    "            except KeyError as e:\n",
    "                print(f\"Error: Entity not found in en_label_dict: {e}\")\n",
    "                print(f\"Relationship: {rel}\")\n",
    "                print(\"Skipping this relationship...🚬\")\n",
    "                continue\n",
    "\n",
    "            cypher = f\"MERGE (a:{source_label} {{id: '{source_id}'}}) MERGE (b:{target_label} {{id: '{target_id}'}}) MERGE (a)-[:{rel_type}]->(b)\" \n",
    "            rel_statements.append(cypher)      \n",
    "\n",
    "    with open(f\"cypher.txt\", \"w\") as outfile:\n",
    "        outfile.write(\"\\n\".join(en_statements + rel_statements))\n",
    "    \n",
    "    return en_statements + rel_statements\n",
    "\n",
    "\n",
    "# Function to bring all steps together\n",
    "def run_pipeline(folders):\n",
    "    # Extracting the entites and relationships from each folder, append into one json_obj\n",
    "    entities_relationships =[]\n",
    "\n",
    "    # Unstructured raw data -> JSON-object\n",
    "    for key, value in folders.items():\n",
    "        entities_relationships.extend(extract_entities_relationships(key, value))\n",
    "    \n",
    "    # Generate and execute cypher statements\n",
    "    # JSON-object -> Cypher statements\n",
    "    cypher_statements = generate_cypher(entities_relationships)\n",
    "    for _, stmts in enumerate(cypher_statements):\n",
    "        print(f\"Executing Cypher statements for file {_ + 1} of {len(cypher_statements)}\")\n",
    "        try:\n",
    "            gds.execute_query(stmts)\n",
    "        except Exception as e:\n",
    "            with open(\"falied_cypher.txt\", \"w\") as f:\n",
    "                f.write(f\"{stmts} - Exception: {e}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test generate_cypher function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Cypher for file 1 of 7\n",
      "Error: Entity not found in en_label_dict: 'noahWilson'\n",
      "Relationship: noahWilson|SENT|6ec813a60\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'aidenLewis'\n",
      "Relationship: aidenLewis|SENT|4203972ad\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'benjaminWhite'\n",
      "Relationship: benjaminWhite|SENT|f230a0f7a\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'sophiaAnderson'\n",
      "Relationship: sophiaAnderson|SENT|843bab5fa\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'sophiaAnderson'\n",
      "Relationship: sophiaAnderson|SENT|408133de0\n",
      "Skipping this relationship...🚬\n",
      "Generating Cypher for file 2 of 7\n",
      "Error: Entity not found in en_label_dict: 'noahWilson'\n",
      "Relationship: noahWilson|SENT|6ec813a60\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'aidenLewis'\n",
      "Relationship: aidenLewis|SENT|4203972ad\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'benjaminWhite'\n",
      "Relationship: benjaminWhite|SENT|f230a0f7a\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'sophiaAnderson'\n",
      "Relationship: sophiaAnderson|SENT|843bab5fa\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'sophiaAnderson'\n",
      "Relationship: sophiaAnderson|SENT|408133de0\n",
      "Skipping this relationship...🚬\n",
      "Generating Cypher for file 3 of 7\n",
      "Generating Cypher for file 4 of 7\n",
      "Error: Entity not found in en_label_dict: 'oliviaMartinez'\n",
      "Relationship: oliviaMartinez|SENT|heaas\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'williamLee'\n",
      "Relationship: williamLee|SENT|jsssa\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'sarahJohnson'\n",
      "Relationship: sarahJohnson|SENT|ppaa\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'davidPatel'\n",
      "Relationship: davidPatel|SENT|gfdd\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'emilyTurner'\n",
      "Relationship: emilyTurner|SENT|lopyyy\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'jasonMitchell'\n",
      "Relationship: jasonMitchell|SENT|fgtttta\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'oliviaMartinez'\n",
      "Relationship: oliviaMartinez|SENT|pldfpaks\n",
      "Skipping this relationship...🚬\n",
      "Generating Cypher for file 5 of 7\n",
      "Error: Entity not found in en_label_dict: 'michaelClark'\n",
      "Relationship: michaelClark|SENT|ytthf\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'jessicaWhite'\n",
      "Relationship: jessicaWhite|SENT|agaer\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'danielBrown'\n",
      "Relationship: danielBrown|SENT|bbtgg\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'michaelClark'\n",
      "Relationship: michaelClark|SENT|gapaa\n",
      "Skipping this relationship...🚬\n",
      "Generating Cypher for file 6 of 7\n",
      "Error: Entity not found in en_label_dict: 'michaelClark'\n",
      "Relationship: michaelClark|SENT|ytthf\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'jessicaWhite'\n",
      "Relationship: jessicaWhite|SENT|agaer\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'danielBrown'\n",
      "Relationship: danielBrown|SENT|bbtgg\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'michaelClark'\n",
      "Relationship: michaelClark|SENT|gapaa\n",
      "Skipping this relationship...🚬\n",
      "Generating Cypher for file 7 of 7\n",
      "Error: Entity not found in en_label_dict: 'michaelClark'\n",
      "Relationship: michaelClark|SENT|ytthf\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'jessicaWhite'\n",
      "Relationship: jessicaWhite|SENT|agaer\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'danielBrown'\n",
      "Relationship: danielBrown|SENT|bbtgg\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'michaelClark'\n",
      "Relationship: michaelClark|SENT|gapaa\n",
      "Skipping this relationship...🚬\n"
     ]
    }
   ],
   "source": [
    "with open('test_slack_msg.json', 'r') as f:\n",
    "    json_obj = json.load(f)\n",
    "\n",
    "cypher = generate_cypher(json_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Extract function can successfully extract entities and relationship from files in data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running pipeline for 3 files in people_profiles folder\n",
      "Extracting entities and relationships for ./data/people_profiles/people-profiles1.md\n",
      "Error processing ./data/people_profiles/people-profiles1.md: [Errno 63] File name too long: 'Here is the extracted information in JSON format:\\n\\n```json\\n{\\n  \"entities\": [\\n    {\\n      \"label\": \"Project\",\\n      \"id\": \"betahealth-secure-healthcare-data-analytics-platform-on-azure\",\\n      \"name\": \"BetaHealth Secure Healthcare Data Analytics Platform on Azure\",\\n      \"summary\": \"A project for BetaHealth that involves secure healthcare data analytics platform on Azure.\"\\n    },\\n    {\\n      \"label\": \"Project\",\\n      \"id\": \"gammatech-smart-logistics-platform-on-azure\",\\n      \"name\": \"GammaTech Smart Logistics Platform on Azure\",\\n      \"summary\": \"A project for GammaTech that involves smart logistics platform on Azure.\"\\n    },\\n    {\\n      \"label\": \"Project\",\\n      \"id\": \"alphacorp-aws-powered-supply-chain-optimization-platform\",\\n      \"name\": \"AlphaCorp AWS-Powered Supply Chain Optimization Platform\",\\n      \"summary\": \"A project for AlphaCorp that involves supply chain optimization platform powered by AWS.\"\\n    },\\n    {\\n      \"label\": \"Client\",\\n      \"id\": \"betahealth\",\\n      \"name\": \"BetaHealth\",\\n      \"industry\": \"Healthcare\"\\n    },\\n    {\\n      \"label\": \"Client\",\\n      \"id\": \"gammatech\",\\n      \"name\": \"GammaTech\",\\n      \"industry\": \"Logistics\"\\n    },\\n    {\\n      \"label\": \"Client\",\\n      \"id\": \"alphacorp\",\\n      \"name\": \"AlphaCorp\",\\n      \"industry\": \"Supply Chain Management\"\\n    },\\n    {\\n      \"label\": \"Technology\",\\n      \"id\": \"azure\",\\n      \"name\": \"Azure\"\\n    },\\n    {\\n      \"label\": \"Technology\",\\n      \"id\": \"aws\",\\n      \"name\": \"AWS\"\\n    }\\n  ],\\n  \"relationships\": [\\n    [\"betahealth-secure-healthcare-data-analytics-platform-on-azure\", \"HAS_CLIENT\", \"betahealth\"],\\n    [\"betahealth-secure-healthcare-data-analytics-platform-on-azure\", \"USES_TECH\", \"azure\"],\\n    [\"gammatech-smart-logistics-platform-on-azure\", \"HAS_CLIENT\", \"gammatech\"],\\n    [\"gammatech-smart-logistics-platform-on-azure\", \"USES_TECH\", \"azure\"],\\n    [\"alphacorp-aws-powered-supply-chain-optimization-platform\", \"HAS_CLIENT\", \"alphacorp\"],\\n    [\"alphacorp-aws-powered-supply-chain-optimization-platform\", \"USES_TECH\", \"aws\"]\\n  ]\\n}\\n```\\n\\nNote: I\\'ve generated the `id` properties for each entity by following the specified format. The `summary` property is a brief summary of each project, and the relationships are defined as triples with the head entity, relationship type, and tail entity.'\n",
      "Extracting entities and relationships for ./data/people_profiles/people-profiles3.md\n",
      "Error processing ./data/people_profiles/people-profiles3.md: [Errno 63] File name too long: 'Here is the extracted information in JSON format:\\n\\n```json\\n{\\n  \"entities\": [\\n    {\\n      \"label\": \"Project\",\\n      \"id\": \"alphacorp-aws-powered-sales-analytics-dashboard\",\\n      \"name\": \"AlphaCorp AWS-Powered Sales Analytics Dashboard\",\\n      \"summary\": \"A sales analytics dashboard powered by AWS for AlphaCorp.\"\\n    },\\n    {\\n      \"label\": \"Project\",\\n      \"id\": \"delt-edu-virtual-classroom-platform-on-aws\",\\n      \"name\": \"DeltaEdu Virtual Classroom Platform on AWS\",\\n      \"summary\": \"A virtual classroom platform built on AWS for DeltaEdu.\"\\n    },\\n    {\\n      \"label\": \"Project\",\\n      \"id\": \"gammatech-iot-driven-manufacturing-monitoring-system-on-azure\",\\n      \"name\": \"GammaTech IoT-Driven Manufacturing Monitoring System on Azure\",\\n      \"summary\": \"An IoT-driven manufacturing monitoring system built on Azure for GammaTech.\"\\n    },\\n    {\\n      \"label\": \"Project\",\\n      \"id\": \"betathealth-telemedicine-platform-on-microsoft-azure\",\\n      \"name\": \"BetaHealth Telemedicine Platform on Microsoft Azure\",\\n      \"summary\": \"A telemedicine platform built on Microsoft Azure for BetaHealth.\"\\n    },\\n    {\\n      \"label\": \"Project\",\\n      \"id\": \"epsilonfinance-mobile-first-digital-wallet-on-google-cloud\",\\n      \"name\": \"EpsilonFinance Mobile-First Digital Wallet on Google Cloud\",\\n      \"summary\": \"A mobile-first digital wallet built on Google Cloud for EpsilonFinance.\"\\n    },\\n    {\\n      \"label\": \"Project\",\\n      \"id\": \"delt-edu-ai-powered-student-performance-analytics-on-aws\",\\n      \"name\": \"DeltaEdu AI-Powered Student Performance Analytics on AWS\",\\n      \"summary\": \"An AI-powered student performance analytics system built on AWS for DeltaEdu.\"\\n    },\\n    {\\n      \"label\": \"Project\",\\n      \"id\": \"alphacorp-aws-powered-sales-analytics-dashboard\",\\n      \"name\": \"AlphaCorp AWS-Powered Sales Analytics Dashboard\",\\n      \"summary\": \"A sales analytics dashboard powered by AWS for AlphaCorp.\"\\n    },\\n    {\\n      \"label\": \"Project\",\\n      \"id\": \"delt-edu-virtual-classroom-platform-on-aws\",\\n      \"name\": \"DeltaEdu Virtual Classroom Platform on AWS\",\\n      \"summary\": \"A virtual classroom platform built on AWS for DeltaEdu.\"\\n    },\\n    {\\n      \"label\": \"Technology\",\\n      \"id\": \"aws\",\\n      \"name\": \"AWS\"\\n    },\\n    {\\n      \"label\": \"Technology\",\\n      \"id\": \"azure\",\\n      \"name\": \"Azure\"\\n    },\\n    {\\n      \"label\": \"Client\",\\n      \"id\": \"alphacorp\",\\n      \"name\": \"AlphaCorp\",\\n      \"industry\": \"Finance\"\\n    },\\n    {\\n      \"label\": \"Client\",\\n      \"id\": \"delt-edu\",\\n      \"name\": \"DeltaEdu\",\\n      \"industry\": \"Education\"\\n    },\\n    {\\n      \"label\": \"Client\",\\n      \"id\": \"gammatech\",\\n      \"name\": \"GammaTech\",\\n      \"industry\": \"Manufacturing\"\\n    },\\n    {\\n      \"label\": \"Client\",\\n      \"id\": \"betathealth\",\\n      \"name\": \"BetaHealth\",\\n      \"industry\": \"Healthcare\"\\n    },\\n    {\\n      \"label\": \"Client\",\\n      \"id\": \"epsilonfinance\",\\n      \"name\": \"EpsilonFinance\",\\n      \"industry\": \"Finance\"\\n    }\\n  ],\\n  \"relationships\": [\\n    \"alphacorp-aws-powered-sales-analytics-dashboard|USES_TECH|aws\",\\n    \"delt-edu-virtual-classroom-platform-on-aws|USES_TECH|aws\",\\n    \"gammatech-iot-driven-manufacturing-monitoring-system-on-azure|USES_TECH|azure\",\\n    \"betathealth-telemedicine-platform-on-microsoft-azure|USES_TECH|microsoft azure\",\\n    \"epsilonfinance-mobile-first-digital-wallet-on-google-cloud|USES_TECH|google cloud\",\\n    \"delt-edu-ai-powered-student-performance-analytics-on-aws|HAS_CLIENT|alphacorp\",\\n    \"alphacorp-aws-powered-sales-analytics-dashboard|HAS_CLIENT|alphacorp\",\\n    \"delt-edu-virtual-classroom-platform-on-aws|HAS_CLIENT|delt-edu\",\\n    \"gammatech-iot-driven-manufacturing-monitoring-system-on-azure|HAS_CLIENT|gammatech\",\\n    \"betathealth-telemedicine-platform-on-microsoft-azure|HAS_CLIENT|betathealth\",\\n    \"epsilonfinance-mobile-first-digital-wallet-on-google-cloud|HAS_CLIENT|epsilonfinance\"\\n  ]\\n}\\n```'\n",
      "Extracting entities and relationships for ./data/people_profiles/people-profiles2.md\n",
      "Error processing ./data/people_profiles/people-profiles2.md: [Errno 63] File name too long: 'Here is the extracted information in JSON format:\\n\\n```json\\n{\\n  \"entities\": [\\n    {\\n      \"label\": \"Project\",\\n      \"id\": \"alphacorp_aws_powered_sales_analytics_dashboard\",\\n      \"name\": \"AlphaCorp AWS-Powered Sales Analytics Dashboard\",\\n      \"summary\": \"A sales analytics dashboard powered by AWS for AlphaCorp.\"\\n    },\\n    {\\n      \"label\": \"Technology\",\\n      \"id\": \"aws\",\\n      \"name\": \"AWS\"\\n    },\\n    {\\n      \"label\": \"Client\",\\n      \"id\": \"alphacorp\",\\n      \"name\": \"AlphaCorp\",\\n      \"industry\": \"Finance\"\\n    },\\n    {\\n      \"label\": \"Project\",\\n      \"id\": \"gammatech_iot_driven_manufacturing_monitoring_system_on_azure\",\\n      \"name\": \"GammaTech IoT-Driven Manufacturing Monitoring System on Azure\",\\n      \"summary\": \"A manufacturing monitoring system powered by Azure for GammaTech.\"\\n    },\\n    {\\n      \"label\": \"Technology\",\\n      \"id\": \"azure\",\\n      \"name\": \"Azure\"\\n    },\\n    {\\n      \"label\": \"Client\",\\n      \"id\": \"gammatech\",\\n      \"name\": \"GammaTech\",\\n      \"industry\": \"Manufacturing\"\\n    },\\n    {\\n      \"label\": \"Project\",\\n      \"id\": \"betathealth_telemedicine_platform_on_microsoft_azure\",\\n      \"name\": \"BetaHealth Telemedicine Platform on Microsoft Azure\",\\n      \"summary\": \"A telemedicine platform powered by Microsoft Azure for BetaHealth.\"\\n    },\\n    {\\n      \"label\": \"Technology\",\\n      \"id\": \"microsoft_azure\",\\n      \"name\": \"Microsoft Azure\"\\n    },\\n    {\\n      \"label\": \"Client\",\\n      \"id\": \"betathealth\",\\n      \"name\": \"BetaHealth\",\\n      \"industry\": \"Healthcare\"\\n    },\\n    {\\n      \"label\": \"Project\",\\n      \"id\": \"deltedu_ai_powered_student_performance_analytics_on_aws\",\\n      \"name\": \"DeltaEdu AI-Powered Student Performance Analytics on AWS\",\\n      \"summary\": \"A student performance analytics system powered by AWS for DeltaEdu.\"\\n    },\\n    {\\n      \"label\": \"Technology\",\\n      \"id\": \"aws\"\\n    },\\n    {\\n      \"label\": \"Client\",\\n      \"id\": \"deltedu\",\\n      \"name\": \"DeltaEdu\",\\n      \"industry\": \"Education\"\\n    },\\n    {\\n      \"label\": \"Project\",\\n      \"id\": \"betathealth_telemedicine_platform_on_microsoft_azure\",\\n      \"name\": \"BetaHealth Telemedicine Platform on Microsoft Azure\",\\n      \"summary\": \"A telemedicine platform powered by Microsoft Azure for BetaHealth.\"\\n    },\\n    {\\n      \"label\": \"Technology\",\\n      \"id\": \"microsoft_azure\"\\n    },\\n    {\\n      \"label\": \"Client\",\\n      \"id\": \"betathealth\"\\n    },\\n    {\\n      \"label\": \"Project\",\\n      \"id\": \"gammatech_iot_driven_manufacturing_monitoring_system_on_azure\",\\n      \"name\": \"GammaTech IoT-Driven Manufacturing Monitoring System on Azure\",\\n      \"summary\": \"A manufacturing monitoring system powered by Azure for GammaTech.\"\\n    },\\n    {\\n      \"label\": \"Technology\",\\n      \"id\": \"azure\"\\n    },\\n    {\\n      \"label\": \"Client\",\\n      \"id\": \"gammatech\"\\n    },\\n    {\\n      \"label\": \"Project\",\\n      \"id\": \"deltedu_ai_powered_student_performance_analytics_on_aws\",\\n      \"name\": \"DeltaEdu AI-Powered Student Performance Analytics on AWS\",\\n      \"summary\": \"A student performance analytics system powered by AWS for DeltaEdu.\"\\n    },\\n    {\\n      \"label\": \"Technology\",\\n      \"id\": \"aws\"\\n    },\\n    {\\n      \"label\": \"Client\",\\n      \"id\": \"deltedu\"\\n    }\\n  ],\\n  \"relationships\": [\\n    \"alphacorp_aws_powered_sales_analytics_dashboard|USES_TECH|aws\",\\n    \"alphacorp_aws_powered_sales_analytics_dashboard|HAS_CLIENT|alphacorp\",\\n    \"gammatech_iot_driven_manufacturing_monitoring_system_on_azure|USES_TECH|azure\",\\n    \"gammatech_iot_driven_manufacturing_monitoring_system_on_azure|HAS_CLIENT|gammatech\",\\n    \"betathealth_telemedicine_platform_on_microsoft_azure|USES_TECH|microsoft_azure\",\\n    \"betathealth_telemedicine_platform_on_microsoft_azure|HAS_CLIENT|betathealth\",\\n    \"deltedu_ai_powered_student_performance_analytics_on_aws|USES_TECH|aws\",\\n    \"deltedu_ai_powered_student_performance_analytics_on_aws|HAS_CLIENT|deltedu\",\\n    \"betathealth_telemedicine_platform_on_microsoft_azure|USES_TECH|microsoft_azure\",\\n    \"betathealth_telemedicine_platform_on_microsoft_azure|HAS_CLIENT|betathealth\",\\n    \"gammatech_iot_driven_manufacturing_monitoring_system_on_azure|USES_TECH|azure\",\\n    \"gammatech_iot_driven_manufacturing_monitoring_system_on_azure|HAS_CLIENT|gammatech\",\\n    \"deltedu_ai_powered_student_performance_analytics_on_aws|USES_TECH|aws\",\\n    \"deltedu_ai_powered_student_performance_analytics_on_aws|HAS_CLIENT|deltedu\"\\n  ]\\n}\\n```'\n",
      "Pipeline completed in 148.78386450000107 seconds\n"
     ]
    }
   ],
   "source": [
    "project_prompt_template = \"\"\"\n",
    "From the Project Brief below, extract the following Entities & relationships described in the mentioned format \n",
    "0. ALWAYS FINISH THE OUTPUT. Never send partial responses\n",
    "1. First, look for these Entity types in the text and generate as comma-separated format similar to entity type.\n",
    "   `id` property of each entity must be alphanumeric and must be unique among the entities. You will be referring this property to define the relationship between entities. Do not create new entity types that aren't mentioned below. Document must be summarized and stored inside Project entity under `summary` property. You will have to generate as many entities as needed as per the types below:\n",
    "    Entity Types:\n",
    "    label:'Project',id:string,name:string;summary:string //Project mentioned in the brief; `id` property is the full name of the project, in lowercase, with no capital letters, special characters, spaces or hyphens; Contents of original document must be summarized inside 'summary' property\n",
    "    label:'Technology',id:string,name:string //Technology Entity; `id` property is the name of the technology, in camel-case. Identify as many of the technologies used as possible\n",
    "    label:'Client',id:string,name:string;industry:string //Client that the project was done for; `id` property is the name of the Client, in camel-case; 'industry' is the industry that the client operates in, as mentioned in the project brief.\n",
    "    \n",
    "2. Next generate each relationships as triples of head, relationship and tail. To refer the head and tail entity, use their respective `id` property. Relationship property should be mentioned within brackets as comma-separated. They should follow these relationship types below. You will have to generate as many relationships as needed as defined below:\n",
    "    Relationship types:\n",
    "    project|USES_TECH|technology \n",
    "    project|HAS_CLIENT|client\n",
    "\n",
    "\n",
    "3. The output should look like :\n",
    "{\n",
    "    \"entities\": [{\"label\":\"Project\",\"id\":string,\"name\":string,\"summary\":string}],\n",
    "    \"relationships\": [\"projectid|USES_TECH|technologyid\"]\n",
    "}\n",
    "\n",
    "Case Sheet:\n",
    "$ctext\n",
    "\"\"\"\n",
    "\n",
    "people_prompt_template = \"\"\"From the list of people below, extract the following Entities & relationships described in the mentioned format \n",
    "0. ALWAYS FINISH THE OUTPUT. Never send partial responses\n",
    "1. First, look for these Entity types in the text and generate as comma-separated format similar to entity type.\n",
    "   `id` property of each entity must be alphanumeric and must be unique among the entities. You will be referring this property to define the relationship between entities. Do not create new entity types that aren't mentioned below. You will have to generate as many entities as needed as per the types below:\n",
    "    Entity Types:\n",
    "    label:'Person',id:string,name:string //Person that the data is about. `id` property is the name of the person, in camel-case. 'name' is the person's name, as spelled in the text.\n",
    "    label:'Project',id:string,name:string;summary:string //Project mentioned in the profile; `id` property is the full lowercase name of the project, with no capital letters, special characters, spaces or hyphens.\n",
    "    label:'Technology',id:string,name:string //Technology Entity, as listed in the \"skills\"-section of every person; `id` property is the name of the technology, in camel-case.\n",
    "    \n",
    "2. Next generate each relationships as triples of head, relationship and tail. To refer the head and tail entity, use their respective `id` property. Relationship property should be mentioned within brackets as comma-separated. They should follow these relationship types below. You will have to generate as many relationships as needed as defined below:\n",
    "    Relationship types:\n",
    "    person|HAS_SKILLS|technology \n",
    "    project|HAS_PEOPLE|person\n",
    "\n",
    "\n",
    "3. The output should look like :\n",
    "{\n",
    "    \"entities\": [{\"label\":\"Person\",\"id\":string,\"name\":string}],\n",
    "    \"relationships\": [\"projectid|HAS_PEOPLE|personid\"]\n",
    "}\n",
    "\n",
    "Case Sheet:\n",
    "$ctext\n",
    "\"\"\"\n",
    "\n",
    "# result = extract_entities_relationships('people_profiles', project_prompt_template)\n",
    "# with open('test_pople_llama3.json', 'w') as f:\n",
    "#     json.dump(result, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_prompt_template = \"\"\"\n",
    "From the Project Brief below, extract the following Entities & relationships described in the mentioned format \n",
    "0. ALWAYS FINISH THE OUTPUT. Never send partial responses\n",
    "1. First, look for these Entity types in the text and generate as comma-separated format similar to entity type.\n",
    "   `id` property of each entity must be alphanumeric and must be unique among the entities. You will be referring this property to define the relationship between entities. Do not create new entity types that aren't mentioned below. Document must be summarized and stored inside Project entity under `summary` property. You will have to generate as many entities as needed as per the types below:\n",
    "    Entity Types:\n",
    "    label:'Project',id:string,name:string;summary:string //Project mentioned in the brief; `id` property is the full name of the project, in lowercase, with no capital letters, special characters, spaces or hyphens; Contents of original document must be summarized inside 'summary' property\n",
    "    label:'Technology',id:string,name:string //Technology Entity; `id` property is the name of the technology, in camel-case. Identify as many of the technologies used as possible\n",
    "    label:'Client',id:string,name:string;industry:string //Client that the project was done for; `id` property is the name of the Client, in camel-case; 'industry' is the industry that the client operates in, as mentioned in the project brief.\n",
    "    \n",
    "2. Next generate each relationships as triples of head, relationship and tail. To refer the head and tail entity, use their respective `id` property. Relationship property should be mentioned within brackets as comma-separated. They should follow these relationship types below. You will have to generate as many relationships as needed as defined below:\n",
    "    Relationship types:\n",
    "    project|USES_TECH|technology \n",
    "    project|HAS_CLIENT|client\n",
    "\n",
    "\n",
    "3. The output should look like :\n",
    "{\n",
    "    \"entities\": [{\"label\":\"Project\",\"id\":string,\"name\":string,\"summary\":string}],\n",
    "    \"relationships\": [\"projectid|USES_TECH|technologyid\"]\n",
    "}\n",
    "\n",
    "Case Sheet:\n",
    "$ctext\n",
    "\"\"\"\n",
    "\n",
    "people_prompt_template = \"\"\"From the list of people below, extract the following Entities & relationships described in the mentioned format \n",
    "0. ALWAYS FINISH THE OUTPUT. Never send partial responses\n",
    "1. First, look for these Entity types in the text and generate as comma-separated format similar to entity type.\n",
    "   `id` property of each entity must be alphanumeric and must be unique among the entities. You will be referring this property to define the relationship between entities. Do not create new entity types that aren't mentioned below. You will have to generate as many entities as needed as per the types below:\n",
    "    Entity Types:\n",
    "    label:'Person',id:string,name:string //Person that the data is about. `id` property is the name of the person, in camel-case. 'name' is the person's name, as spelled in the text.\n",
    "    label:'Project',id:string,name:string;summary:string //Project mentioned in the profile; `id` property is the full lowercase name of the project, with no capital letters, special characters, spaces or hyphens.\n",
    "    label:'Technology',id:string,name:string //Technology Entity, as listed in the \"skills\"-section of every person; `id` property is the name of the technology, in camel-case.\n",
    "    \n",
    "2. Next generate each relationships as triples of head, relationship and tail. To refer the head and tail entity, use their respective `id` property. Relationship property should be mentioned within brackets as comma-separated. They should follow these relationship types below. You will have to generate as many relationships as needed as defined below:\n",
    "    Relationship types:\n",
    "    person|HAS_SKILLS|technology \n",
    "    project|HAS_PEOPLE|person\n",
    "\n",
    "\n",
    "3. The output should look like :\n",
    "{\n",
    "    \"entities\": [{\"label\":\"Person\",\"id\":string,\"name\":string}],\n",
    "    \"relationships\": [\"projectid|HAS_PEOPLE|personid\"]\n",
    "}\n",
    "\n",
    "Case Sheet:\n",
    "$ctext\n",
    "\"\"\"\n",
    "\n",
    "slack_prompt_template = \"\"\"\n",
    "From the list of messages below, extract the following Entities & relationships described in the mentioned format \n",
    "0. ALWAYS FINISH THE OUTPUT. Never send partial responses\n",
    "1. First, look for these Entity types in the text and generate as comma-separated format similar to entity type.\n",
    "   `id` property of each entity must be alphanumeric and must be unique among the entities. You will be referring this property to define the relationship between entities. Do not create new entity types that aren't mentioned below. You will have to generate as many entities as needed as per the types below:\n",
    "    Entity Types:\n",
    "    label:'Person',id:string,name:string //Person that sent the message. `id` property is the name of the person, in camel-case; for example, \"michaelClark\", or \"emmaMartinez\"; 'name' is the person's name, as spelled in the text.\n",
    "    label:'SlackMessage',id:string,text:string //The Slack-Message that was sent; 'id' property should be the message id, as spelled in the reference. 'text' property is the text content of the message, as spelled in the reference\n",
    "    \n",
    "3. Next generate each relationships as triples of head, relationship and tail. To refer the head and tail entity, use their respective `id` property. Relationship property should be mentioned within brackets as comma-separated. They should follow these relationship types below. You will have to generate as many relationships as needed as defined below:\n",
    "    Relationship types:\n",
    "    personid|SENT|slackmessageid\n",
    "\n",
    "The output should look like :\n",
    "{\n",
    "    \"entities\": [{\"label\":\"SlackMessage\",\"id\":string,\"text\":string}],\n",
    "    \"relationships\": [\"personid|SENT|messageid\"]\n",
    "}\n",
    "\n",
    "Case Sheet:\n",
    "$ctext\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the pipeline for all files in data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running pipeline for 3 files in people_profiles folder.\n",
      "\n",
      "Processing file 1/3: ./data/people_profiles/people-profiles1.md .\n",
      "Attemping to parse JSON...\n",
      "JSON parsed successfully\n",
      "\n",
      "Processing file 2/3: ./data/people_profiles/people-profiles3.md .\n",
      "Attemping to parse JSON...\n",
      "JSON parsed successfully\n",
      "\n",
      "Processing file 3/3: ./data/people_profiles/people-profiles2.md .\n",
      "Attemping to parse JSON...\n",
      "JSON parsed successfully\n",
      "\n",
      "Pipeline completed in 179.86132937500952 seconds\n",
      "Running pipeline for 11 files in project_briefs folder.\n",
      "\n",
      "Processing file 1/11: ./data/project_briefs/BetaHealth Telemedicine Platform on Microsoft Azure.md .\n",
      "Attemping to parse JSON...\n",
      "JSON parsed successfully\n",
      "\n",
      "Processing file 2/11: ./data/project_briefs/DeltaEdu Virtual Classroom Platform on AWS.md .\n",
      "Attemping to parse JSON...\n",
      "JSON parsed successfully\n",
      "\n",
      "Processing file 3/11: ./data/project_briefs/GammaTech Autonomous Fleet Management System on Azure.md .\n",
      "Attemping to parse JSON...\n",
      "JSON parsed successfully\n",
      "\n",
      "Processing file 4/11: ./data/project_briefs/GammaTech Smart Logistics Platform on Azure.md .\n",
      "Attemping to parse JSON...\n",
      "JSON parsed successfully\n",
      "\n",
      "Processing file 5/11: ./data/project_briefs/AlphaCorp Customer Support Chatbot.md .\n",
      "Attemping to parse JSON...\n",
      "JSON parsed successfully\n",
      "\n",
      "Processing file 6/11: ./data/project_briefs/BetaHealth Secure Healthcare Data Analytics Platform on Azure.md .\n",
      "Attemping to parse JSON...\n",
      "JSON parsed successfully\n",
      "\n",
      "Processing file 7/11: ./data/project_briefs/AlphaCorp AWS-Powered Sales Analytics Dashboard.md .\n",
      "Attemping to parse JSON...\n",
      "JSON parsed successfully\n",
      "\n",
      "Processing file 8/11: ./data/project_briefs/AlphaCorp Supply Chain Optimization Platform.md .\n",
      "Attemping to parse JSON...\n",
      "JSON parsed successfully\n",
      "\n",
      "Processing file 9/11: ./data/project_briefs/EpsilonFinance Mobile-First Digital Wallet on Google Cloud.md .\n",
      "Attemping to parse JSON...\n",
      "JSON parsed successfully\n",
      "\n",
      "Processing file 10/11: ./data/project_briefs/BetaHealth AI-Driven Patient Care Enhancement Platform on Azure.md .\n",
      "Attemping to parse JSON...\n",
      "JSON parsed successfully\n",
      "\n",
      "Processing file 11/11: ./data/project_briefs/DeltaEdu AI-Powered Student Performance Analytics on AWS.md .\n",
      "Attemping to parse JSON...\n",
      "JSON parsed successfully\n",
      "\n",
      "Pipeline completed in 287.2872341249895 seconds\n",
      "Running pipeline for 7 files in slack_messages folder.\n",
      "\n",
      "Processing file 1/7: ./data/slack_messages/slack_messages6.json .\n",
      "Attemping to parse JSON...\n",
      "JSON parsed successfully\n",
      "\n",
      "Processing file 2/7: ./data/slack_messages/slack_messages7.json .\n",
      "Attemping to parse JSON...\n",
      "JSON parsing error: Expecting ',' delimiter: line 16 column 39 (char 1497)\n",
      "Full raw result:\n",
      " {\n",
      "      \"entities\": [\n",
      "          {\"label\":\"Person\",\"id\":\"liamThompson\",\"name\":\"Liam Thompson\"},\n",
      "          {\"label\":\"SlackMessage\",\"id\":\"f17f60cc-0\",\"text\":\"The virtual representation of the manufacturing unit using Azure Digital Twins for GammaTech is fascinating. It's like having a digital twin of the entire facility.\"},\n",
      "          {\"label\":\"Person\",\"id\":\"lucasTaylor\",\"name\":\"Lucas Taylor\"},\n",
      "          {\"label\":\"SlackMessage\",\"id\":\"01e37dce-1\",\"text\":\"The Virtual Classroom Platform for DeltaEdu on AWS is shaping up really well. The real-time quizzes feature is a hit!\"},\n",
      "          {\"label\":\"Person\",\"id\":\"emmaMartinez\",\"name\":\"Emma Martinez\"},\n",
      "          {\"label\":\"SlackMessage\",\"id\":\"158f781f-8\",\"text\":\"GammaTech's Manufacturing Monitoring System has significantly reduced downtimes. Real-time monitoring is the future.\"},\n",
      "          {\"label\":\"Person\",\"id\":\"isabellaHarris\",\"name\":\"Isabella Harris\"},\n",
      "          {\"label\":\"SlackMessage\",\"id\":\"afc5f40e-b\",\"text\":\"EpsilonFinance's Digital Wallet is so user-friendly. The integration with Google Pay APIs has made transactions smooth.\"},\n",
      "          {\"label\":\"Person\",\"id\":\"ellaSmith\",\"name\":\"Ella Smith\"},\n",
      "          {\"label\":\"SlackMessage\",\"id\":\"a00bdb25-0\",\"text\":\"The virtual representation of the manufacturing unit using Azure Digital Twins for GammaTech is fascinating. It's like having a digital twin of the entire facility.\"}\n",
      "      ],\n",
      "      \"relationships\": [\n",
      "          \"liamThompson|SENT|f17f60cc-0\",\n",
      "          \"ellaSmith|SENT|a00bdb25-0\" // Add more relationships as needed for the other messages\n",
      "      ]\n",
      "   }\n",
      "\n",
      "Attempting to fix JSON...\n",
      "Fixed JSON successfully\n",
      "\n",
      "Processing file 3/7: ./data/slack_messages/slack_messages1.json .\n",
      "Attemping to parse JSON...\n",
      "JSON parsed successfully\n",
      "\n",
      "Processing file 4/7: ./data/slack_messages/slack_messages2.json .\n",
      "Attemping to parse JSON...\n",
      "JSON parsed successfully\n",
      "\n",
      "Processing file 5/7: ./data/slack_messages/slack_messages3.json .\n",
      "Attemping to parse JSON...\n",
      "JSON parsed successfully\n",
      "\n",
      "Processing file 6/7: ./data/slack_messages/slack_messages4.json .\n",
      "Attemping to parse JSON...\n",
      "JSON parsing error: Expecting value: line 19 column 7 (char 1400)\n",
      "Full raw result:\n",
      " {\n",
      "    \"entities\": [\n",
      "      {\"label\":\"Person\",\"id\":\"emmaMartinez\",\"name\":\"Emma Martinez\"},\n",
      "      {\"label\":\"SlackMessage\",\"id\":\"6cffae64-d\",\"text\":\"EpsilonFinance's Digital Wallet is so user-friendly. The integration with Google Pay APIs has made transactions smooth.\"},\n",
      "      {\"label\":\"Person\",\"id\":\"sophiaAnderson\",\"name\":\"Sophia Anderson\"},\n",
      "      {\"label\":\"SlackMessage\",\"id\":\"c9e872b6-a\",\"text\":\"Securing user data in EpsilonFinance's Digital Wallet has been top priority. Google Cloud's security features have been instrumental.\"},\n",
      "      {\"label\":\"Person\",\"id\":\"avaJackson\",\"name\":\"Ava Jackson\"},\n",
      "      {\"label\":\"SlackMessage\",\"id\":\"944dd6bb-6\",\"text\": \"Has anyone checked the new visualization module in AlphaCorp's dashboard? The insights are so detailed.\"},\n",
      "      {\"label\":\"Person\",\"id\":\"aidenLewis\",\"name\":\"Aiden Lewis\"},\n",
      "      {\"label\":\"SlackMessage\",\"id\":\"a5959a96-6\",\"text\": \"Has anyone checked the new visualization module in AlphaCorp's dashboard? The insights are so detailed.\"},\n",
      "      {\"label\":\"Person\",\"id\":\"lucasTaylor\",\"name\":\"Lucas Taylor\"},\n",
      "      {\"label\":\"SlackMessage\",\"id\":\"3d2b4744-c\",\"text\": \"Has anyone tried the breakout rooms in DeltaEdu's Virtual Classroom? I'd love to get feedback.\"}\n",
      "    ],\n",
      "    \"relationships\": [\n",
      "      \"emmaMartinez|SENT|6cffae64-d\",\n",
      "      \"sophiaAnderson|SENT|c9e872b6-a\",\n",
      "      \"avaJackson|SENT|944dd6bb-6\",\n",
      "      \"aidenLewis|SENT|a5959a96-6\",\n",
      "      // Assuming the same person sent multiple messages with different ids, so no relationship for the last message.\n",
      "    ]\n",
      "  }\n",
      "\n",
      "Attempting to fix JSON...\n",
      "Fixed JSON successfully\n",
      "\n",
      "Processing file 7/7: ./data/slack_messages/slack_messages5.json .\n",
      "Attemping to parse JSON...\n",
      "JSON parsing error: Expecting value: line 18 column 11 (char 1398)\n",
      "Full raw result:\n",
      " {\n",
      "      \"entities\": [\n",
      "          {\"label\":\"Person\",\"id\":\"emmaMartinez\",\"name\":\"Emma Martinez\"},\n",
      "          {\"label\":\"SlackMessage\",\"id\":\"e756c8ae-c\",\"text\":\"Has anyone checked the new visualization module in AlphaCorp's dashboard? The insights are so detailed.\"},\n",
      "          {\"label\":\"Person\",\"id\":\"avaJackson\",\"name\":\"Ava Jackson\"},\n",
      "          {\"label\":\"SlackMessage\",\"id\":\"6674380b-6\",\"text\":\"The personalized learning paths suggested by our AI model for DeltaEdu are spot on. Kudos to the team!\"},\n",
      "          {\"label\":\"Person\",\"id\":\"benjaminWhite\",\"name\":\"Benjamin White\"},\n",
      "          {\"label\":\"SlackMessage\",\"id\":\"241c3938-c\",\"text\":\"Has anyone checked the new visualization module in AlphaCorp's dashboard? The insights are so detailed.\"},\n",
      "          {\"label\":\"Person\",\"id\":\"lucasTaylor\",\"name\":\"Lucas Taylor\"},\n",
      "          {\"label\":\"SlackMessage\",\"id\":\"877c0c6d-3\",\"text\":\"The remote monitoring in BetaHealth's Telemedicine Platform ensures continuous patient care. Azure's scalability made it possible.\"},\n",
      "          {\"label\":\"Person\",\"id\":\"ellaSmith\",\"name\":\"Ella Smith\"},\n",
      "          {\"label\":\"SlackMessage\",\"id\":\"e1bfefde-f\",\"text\":\"Has anyone tried the breakout rooms in DeltaEdu's Virtual Classroom? I'd love to get feedback.\"}\n",
      "      ],\n",
      "      \"relationships\": [\n",
      "          \"emmaMartinez|SENT|e756c8ae-c\",\n",
      "          \"avaJackson|SENT|6674380b-6\",\n",
      "          \"benjaminWhite|SENT|241c3938-c\",\n",
      "          // Add more relationships based on the messages\n",
      "      ]\n",
      "  }\n",
      "\n",
      "Attempting to fix JSON...\n",
      "Fixed JSON successfully\n",
      "\n",
      "Pipeline completed in 186.8309219579969 seconds\n",
      "Generating Cypher for file 1 of 21\n",
      "Error: Entity not found in en_label_dict: 'BetaHealthSecureHealthcareDataAnalyticsPlatformOnAzure'\n",
      "Relationship: BetaHealthSecureHealthcareDataAnalyticsPlatformOnAzure|HAS_PEOPLE|SarahJohnson\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'BetaHealthSecureHealthcareDataAnalyticsPlatformOnAzure'\n",
      "Relationship: BetaHealthSecureHealthcareDataAnalyticsPlatformOnAzure|HAS_PEOPLE|JessicaWhite\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'GammaTechSmartLogisticsPlatformOnAzure'\n",
      "Relationship: GammaTechSmartLogisticsPlatformOnAzure|HAS_PEOPLE|SarahJohnson\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'GammaTechSmartLogisticsPlatformOnAzure'\n",
      "Relationship: GammaTechSmartLogisticsPlatformOnAzure|HAS_PEOPLE|EmilyTurner\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'GammaTechSmartLogisticsPlatformOnAzure'\n",
      "Relationship: GammaTechSmartLogisticsPlatformOnAzure|HAS_PEOPLE|DanielBrown\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'AlphaCorpAWSPoweredSupplyChainOptimizationPlatform'\n",
      "Relationship: AlphaCorpAWSPoweredSupplyChainOptimizationPlatform|HAS_PEOPLE|OliviaMartinez\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'BetaHealthSecureHealthcareDataAnalyticsPlatformOnAzure'\n",
      "Relationship: BetaHealthSecureHealthcareDataAnalyticsPlatformOnAzure|HAS_TECHNOLOGY|MachineLearning\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'BetaHealthSecureHealthcareDataAnalyticsPlatformOnAzure'\n",
      "Relationship: BetaHealthSecureHealthcareDataAnalyticsPlatformOnAzure|HAS_TECHNOLOGY|DataAnalytics\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'BetaHealthSecureHealthcareDataAnalyticsPlatformOnAzure'\n",
      "Relationship: BetaHealthSecureHealthcareDataAnalyticsPlatformOnAzure|HAS_TECHNOLOGY|Azure\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'BetaHealthSecureHealthcareDataAnalyticsPlatformOnAzure'\n",
      "Relationship: BetaHealthSecureHealthcareDataAnalyticsPlatformOnAzure|HAS_TECHNOLOGY|Python\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'GammaTechSmartLogisticsPlatformOnAzure'\n",
      "Relationship: GammaTechSmartLogisticsPlatformOnAzure|HAS_TECHNOLOGY|MachineLearning\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'GammaTechSmartLogisticsPlatformOnAzure'\n",
      "Relationship: GammaTechSmartLogisticsPlatformOnAzure|HAS_TECHNOLOGY|DataAnalytics\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'GammaTechSmartLogisticsPlatformOnAzure'\n",
      "Relationship: GammaTechSmartLogisticsPlatformOnAzure|HAS_TECHNOLOGY|Azure\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'GammaTechSmartLogisticsPlatformOnAzure'\n",
      "Relationship: GammaTechSmartLogisticsPlatformOnAzure|HAS_TECHNOLOGY|Python\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'AlphaCorpAWSPoweredSupplyChainOptimizationPlatform'\n",
      "Relationship: AlphaCorpAWSPoweredSupplyChainOptimizationPlatform|HAS_TECHNOLOGY|DataEngineering\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'AlphaCorpAWSPoweredSupplyChainOptimizationPlatform'\n",
      "Relationship: AlphaCorpAWSPoweredSupplyChainOptimizationPlatform|HAS_TECHNOLOGY|DataWarehousing\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'AlphaCorpAWSPoweredSupplyChainOptimizationPlatform'\n",
      "Relationship: AlphaCorpAWSPoweredSupplyChainOptimizationPlatform|HAS_TECHNOLOGY|AWS\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'AlphaCorpAWSPoweredSupplyChainOptimizationPlatform'\n",
      "Relationship: AlphaCorpAWSPoweredSupplyChainOptimizationPlatform|HAS_TECHNOLOGY|Python\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'BetaHealthSecureHealthcareDataAnalyticsPlatformOnAzure'\n",
      "Relationship: BetaHealthSecureHealthcareDataAnalyticsPlatformOnAzure|HAS_TECHNOLOGY|DataSecurity\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'BetaHealthSecureHealthcareDataAnalyticsPlatformOnAzure'\n",
      "Relationship: BetaHealthSecureHealthcareDataAnalyticsPlatformOnAzure|HAS_TECHNOLOGY|Compliance\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'BetaHealthSecureHealthcareDataAnalyticsPlatformOnAzure'\n",
      "Relationship: BetaHealthSecureHealthcareDataAnalyticsPlatformOnAzure|HAS_TECHNOLOGY|HealthcareRegulations\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'BetaHealthSecureHealthcareDataAnalyticsPlatformOnAzure'\n",
      "Relationship: BetaHealthSecureHealthcareDataAnalyticsPlatformOnAzure|HAS_TECHNOLOGY|AzureKeyVault\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'GammaTechSmartLogisticsPlatformOnAzure'\n",
      "Relationship: GammaTechSmartLogisticsPlatformOnAzure|HAS_TECHNOLOGY|IoT\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'GammaTechSmartLogisticsPlatformOnAzure'\n",
      "Relationship: GammaTechSmartLogisticsPlatformOnAzure|HAS_TECHNOLOGY|RealTimeDataManagement\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'AlphaCorpAWSPoweredSupplyChainOptimizationPlatform'\n",
      "Relationship: AlphaCorpAWSPoweredSupplyChainOptimizationPlatform|HAS_TECHNOLOGY|CloudArchitecture\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'AlphaCorpAWSPoweredSupplyChainOptimizationPlatform'\n",
      "Relationship: AlphaCorpAWSPoweredSupplyChainOptimizationPlatform|HAS_TECHNOLOGY|DevOps\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'AlphaCorpAWSPoweredSupplyChainOptimizationPlatform'\n",
      "Relationship: AlphaCorpAWSPoweredSupplyChainOptimizationPlatform|HAS_TECHNOLOGY|AWSLambda\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'AlphaCorpAWSPoweredSupplyChainOptimizationPlatform'\n",
      "Relationship: AlphaCorpAWSPoweredSupplyChainOptimizationPlatform|HAS_TECHNOLOGY|AzureFunctions\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'GammaTechSmartLogisticsPlatformOnAzure'\n",
      "Relationship: GammaTechSmartLogisticsPlatformOnAzure|HAS_TECHNOLOGY|DataPrivacy\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'GammaTechSmartLogisticsPlatformOnAzure'\n",
      "Relationship: GammaTechSmartLogisticsPlatformOnAzure|HAS_TECHNOLOGY|SecurityCompliance\n",
      "Skipping this relationship...🚬\n",
      "Generating Cypher for file 2 of 21\n",
      "Generating Cypher for file 3 of 21\n",
      "Generating Cypher for file 4 of 21\n",
      "Generating Cypher for file 5 of 21\n",
      "Generating Cypher for file 6 of 21\n",
      "Generating Cypher for file 7 of 21\n",
      "Generating Cypher for file 8 of 21\n",
      "Generating Cypher for file 9 of 21\n",
      "Generating Cypher for file 10 of 21\n",
      "Generating Cypher for file 11 of 21\n",
      "Generating Cypher for file 12 of 21\n",
      "Generating Cypher for file 13 of 21\n",
      "Generating Cypher for file 14 of 21\n",
      "Generating Cypher for file 15 of 21\n",
      "Error: Entity not found in en_label_dict: 'noahWilson'\n",
      "Relationship: noahWilson|SENT|6ec813a60\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'aidenLewis'\n",
      "Relationship: aidenLewis|SENT|4203972ad\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'benjaminWhite'\n",
      "Relationship: benjaminWhite|SENT|f230a0f7a\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'sophiaAnderson'\n",
      "Relationship: sophiaAnderson|SENT|843bab5fa\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'sophiaAnderson'\n",
      "Relationship: sophiaAnderson|SENT|408133de0\n",
      "Skipping this relationship...🚬\n",
      "Generating Cypher for file 16 of 21\n",
      "Error: Entity not found in en_label_dict: 'noahWilson'\n",
      "Relationship: noahWilson|SENT|6ec813a60\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'aidenLewis'\n",
      "Relationship: aidenLewis|SENT|4203972ad\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'benjaminWhite'\n",
      "Relationship: benjaminWhite|SENT|f230a0f7a\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'sophiaAnderson'\n",
      "Relationship: sophiaAnderson|SENT|843bab5fa\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'sophiaAnderson'\n",
      "Relationship: sophiaAnderson|SENT|408133de0\n",
      "Skipping this relationship...🚬\n",
      "Generating Cypher for file 17 of 21\n",
      "Generating Cypher for file 18 of 21\n",
      "Error: Entity not found in en_label_dict: 'oliviaMartinez'\n",
      "Relationship: oliviaMartinez|SENT|heaas\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'williamLee'\n",
      "Relationship: williamLee|SENT|jsssa\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'sarahJohnson'\n",
      "Relationship: sarahJohnson|SENT|ppaa\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'davidPatel'\n",
      "Relationship: davidPatel|SENT|gfdd\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'emilyTurner'\n",
      "Relationship: emilyTurner|SENT|lopyyy\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'jasonMitchell'\n",
      "Relationship: jasonMitchell|SENT|fgtttta\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'oliviaMartinez'\n",
      "Relationship: oliviaMartinez|SENT|pldfpaks\n",
      "Skipping this relationship...🚬\n",
      "Generating Cypher for file 19 of 21\n",
      "Error: Entity not found in en_label_dict: 'michaelClark'\n",
      "Relationship: michaelClark|SENT|ytthf\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'jessicaWhite'\n",
      "Relationship: jessicaWhite|SENT|agaer\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'danielBrown'\n",
      "Relationship: danielBrown|SENT|bbtgg\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'michaelClark'\n",
      "Relationship: michaelClark|SENT|gapaa\n",
      "Skipping this relationship...🚬\n",
      "Generating Cypher for file 20 of 21\n",
      "Error: Entity not found in en_label_dict: 'michaelClark'\n",
      "Relationship: michaelClark|SENT|ytthf\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'jessicaWhite'\n",
      "Relationship: jessicaWhite|SENT|agaer\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'danielBrown'\n",
      "Relationship: danielBrown|SENT|bbtgg\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'michaelClark'\n",
      "Relationship: michaelClark|SENT|gapaa\n",
      "Skipping this relationship...🚬\n",
      "Generating Cypher for file 21 of 21\n",
      "Error: Entity not found in en_label_dict: 'michaelClark'\n",
      "Relationship: michaelClark|SENT|ytthf\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'jessicaWhite'\n",
      "Relationship: jessicaWhite|SENT|agaer\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'danielBrown'\n",
      "Relationship: danielBrown|SENT|bbtgg\n",
      "Skipping this relationship...🚬\n",
      "Error: Entity not found in en_label_dict: 'michaelClark'\n",
      "Relationship: michaelClark|SENT|gapaa\n",
      "Skipping this relationship...🚬\n",
      "Executing Cypher statements for file 1 of 284\n",
      "Executing Cypher statements for file 2 of 284\n",
      "Executing Cypher statements for file 3 of 284\n",
      "Executing Cypher statements for file 4 of 284\n",
      "Executing Cypher statements for file 5 of 284\n",
      "Executing Cypher statements for file 6 of 284\n",
      "Executing Cypher statements for file 7 of 284\n",
      "Executing Cypher statements for file 8 of 284\n",
      "Executing Cypher statements for file 9 of 284\n",
      "Executing Cypher statements for file 10 of 284\n",
      "Executing Cypher statements for file 11 of 284\n",
      "Executing Cypher statements for file 12 of 284\n",
      "Executing Cypher statements for file 13 of 284\n",
      "Executing Cypher statements for file 14 of 284\n",
      "Executing Cypher statements for file 15 of 284\n",
      "Executing Cypher statements for file 16 of 284\n",
      "Executing Cypher statements for file 17 of 284\n",
      "Executing Cypher statements for file 18 of 284\n",
      "Executing Cypher statements for file 19 of 284\n",
      "Executing Cypher statements for file 20 of 284\n",
      "Executing Cypher statements for file 21 of 284\n",
      "Executing Cypher statements for file 22 of 284\n",
      "Executing Cypher statements for file 23 of 284\n",
      "Executing Cypher statements for file 24 of 284\n",
      "Executing Cypher statements for file 25 of 284\n",
      "Executing Cypher statements for file 26 of 284\n",
      "Executing Cypher statements for file 27 of 284\n",
      "Executing Cypher statements for file 28 of 284\n",
      "Executing Cypher statements for file 29 of 284\n",
      "Executing Cypher statements for file 30 of 284\n",
      "Executing Cypher statements for file 31 of 284\n",
      "Executing Cypher statements for file 32 of 284\n",
      "Executing Cypher statements for file 33 of 284\n",
      "Executing Cypher statements for file 34 of 284\n",
      "Executing Cypher statements for file 35 of 284\n",
      "Executing Cypher statements for file 36 of 284\n",
      "Executing Cypher statements for file 37 of 284\n",
      "Executing Cypher statements for file 38 of 284\n",
      "Executing Cypher statements for file 39 of 284\n",
      "Executing Cypher statements for file 40 of 284\n",
      "Executing Cypher statements for file 41 of 284\n",
      "Executing Cypher statements for file 42 of 284\n",
      "Executing Cypher statements for file 43 of 284\n",
      "Executing Cypher statements for file 44 of 284\n",
      "Executing Cypher statements for file 45 of 284\n",
      "Executing Cypher statements for file 46 of 284\n",
      "Executing Cypher statements for file 47 of 284\n",
      "Executing Cypher statements for file 48 of 284\n",
      "Executing Cypher statements for file 49 of 284\n",
      "Executing Cypher statements for file 50 of 284\n",
      "Executing Cypher statements for file 51 of 284\n",
      "Executing Cypher statements for file 52 of 284\n",
      "Executing Cypher statements for file 53 of 284\n",
      "Executing Cypher statements for file 54 of 284\n",
      "Executing Cypher statements for file 55 of 284\n",
      "Executing Cypher statements for file 56 of 284\n",
      "Executing Cypher statements for file 57 of 284\n",
      "Executing Cypher statements for file 58 of 284\n",
      "Executing Cypher statements for file 59 of 284\n",
      "Executing Cypher statements for file 60 of 284\n",
      "Executing Cypher statements for file 61 of 284\n",
      "Executing Cypher statements for file 62 of 284\n",
      "Executing Cypher statements for file 63 of 284\n",
      "Executing Cypher statements for file 64 of 284\n",
      "Executing Cypher statements for file 65 of 284\n",
      "Executing Cypher statements for file 66 of 284\n",
      "Executing Cypher statements for file 67 of 284\n",
      "Executing Cypher statements for file 68 of 284\n",
      "Executing Cypher statements for file 69 of 284\n",
      "Executing Cypher statements for file 70 of 284\n",
      "Executing Cypher statements for file 71 of 284\n",
      "Executing Cypher statements for file 72 of 284\n",
      "Executing Cypher statements for file 73 of 284\n",
      "Executing Cypher statements for file 74 of 284\n",
      "Executing Cypher statements for file 75 of 284\n",
      "Executing Cypher statements for file 76 of 284\n",
      "Executing Cypher statements for file 77 of 284\n",
      "Executing Cypher statements for file 78 of 284\n",
      "Executing Cypher statements for file 79 of 284\n",
      "Executing Cypher statements for file 80 of 284\n",
      "Executing Cypher statements for file 81 of 284\n",
      "Executing Cypher statements for file 82 of 284\n",
      "Executing Cypher statements for file 83 of 284\n",
      "Executing Cypher statements for file 84 of 284\n",
      "Executing Cypher statements for file 85 of 284\n",
      "Executing Cypher statements for file 86 of 284\n",
      "Executing Cypher statements for file 87 of 284\n",
      "Executing Cypher statements for file 88 of 284\n",
      "Executing Cypher statements for file 89 of 284\n",
      "Executing Cypher statements for file 90 of 284\n",
      "Executing Cypher statements for file 91 of 284\n",
      "Executing Cypher statements for file 92 of 284\n",
      "Executing Cypher statements for file 93 of 284\n",
      "Executing Cypher statements for file 94 of 284\n",
      "Executing Cypher statements for file 95 of 284\n",
      "Executing Cypher statements for file 96 of 284\n",
      "Executing Cypher statements for file 97 of 284\n",
      "Executing Cypher statements for file 98 of 284\n",
      "Executing Cypher statements for file 99 of 284\n",
      "Executing Cypher statements for file 100 of 284\n",
      "Executing Cypher statements for file 101 of 284\n",
      "Executing Cypher statements for file 102 of 284\n",
      "Executing Cypher statements for file 103 of 284\n",
      "Executing Cypher statements for file 104 of 284\n",
      "Executing Cypher statements for file 105 of 284\n",
      "Executing Cypher statements for file 106 of 284\n",
      "Executing Cypher statements for file 107 of 284\n",
      "Executing Cypher statements for file 108 of 284\n",
      "Executing Cypher statements for file 109 of 284\n",
      "Executing Cypher statements for file 110 of 284\n",
      "Executing Cypher statements for file 111 of 284\n",
      "Executing Cypher statements for file 112 of 284\n",
      "Executing Cypher statements for file 113 of 284\n",
      "Executing Cypher statements for file 114 of 284\n",
      "Executing Cypher statements for file 115 of 284\n",
      "Executing Cypher statements for file 116 of 284\n",
      "Executing Cypher statements for file 117 of 284\n",
      "Executing Cypher statements for file 118 of 284\n",
      "Executing Cypher statements for file 119 of 284\n",
      "Executing Cypher statements for file 120 of 284\n",
      "Executing Cypher statements for file 121 of 284\n",
      "Executing Cypher statements for file 122 of 284\n",
      "Executing Cypher statements for file 123 of 284\n",
      "Executing Cypher statements for file 124 of 284\n",
      "Executing Cypher statements for file 125 of 284\n",
      "Executing Cypher statements for file 126 of 284\n",
      "Executing Cypher statements for file 127 of 284\n",
      "Executing Cypher statements for file 128 of 284\n",
      "Executing Cypher statements for file 129 of 284\n",
      "Executing Cypher statements for file 130 of 284\n",
      "Executing Cypher statements for file 131 of 284\n",
      "Executing Cypher statements for file 132 of 284\n",
      "Executing Cypher statements for file 133 of 284\n",
      "Executing Cypher statements for file 134 of 284\n",
      "Executing Cypher statements for file 135 of 284\n",
      "Executing Cypher statements for file 136 of 284\n",
      "Executing Cypher statements for file 137 of 284\n",
      "Executing Cypher statements for file 138 of 284\n",
      "Executing Cypher statements for file 139 of 284\n",
      "Executing Cypher statements for file 140 of 284\n",
      "Executing Cypher statements for file 141 of 284\n",
      "Executing Cypher statements for file 142 of 284\n",
      "Executing Cypher statements for file 143 of 284\n",
      "Executing Cypher statements for file 144 of 284\n",
      "Executing Cypher statements for file 145 of 284\n",
      "Executing Cypher statements for file 146 of 284\n",
      "Executing Cypher statements for file 147 of 284\n",
      "Executing Cypher statements for file 148 of 284\n",
      "Executing Cypher statements for file 149 of 284\n",
      "Executing Cypher statements for file 150 of 284\n",
      "Executing Cypher statements for file 151 of 284\n",
      "Executing Cypher statements for file 152 of 284\n",
      "Executing Cypher statements for file 153 of 284\n",
      "Executing Cypher statements for file 154 of 284\n",
      "Executing Cypher statements for file 155 of 284\n",
      "Executing Cypher statements for file 156 of 284\n",
      "Executing Cypher statements for file 157 of 284\n",
      "Executing Cypher statements for file 158 of 284\n",
      "Executing Cypher statements for file 159 of 284\n",
      "Executing Cypher statements for file 160 of 284\n",
      "Executing Cypher statements for file 161 of 284\n",
      "Executing Cypher statements for file 162 of 284\n",
      "Executing Cypher statements for file 163 of 284\n",
      "Executing Cypher statements for file 164 of 284\n",
      "Executing Cypher statements for file 165 of 284\n",
      "Executing Cypher statements for file 166 of 284\n",
      "Executing Cypher statements for file 167 of 284\n",
      "Executing Cypher statements for file 168 of 284\n",
      "Executing Cypher statements for file 169 of 284\n",
      "Executing Cypher statements for file 170 of 284\n",
      "Executing Cypher statements for file 171 of 284\n",
      "Executing Cypher statements for file 172 of 284\n",
      "Executing Cypher statements for file 173 of 284\n",
      "Executing Cypher statements for file 174 of 284\n",
      "Executing Cypher statements for file 175 of 284\n",
      "Executing Cypher statements for file 176 of 284\n",
      "Executing Cypher statements for file 177 of 284\n",
      "Executing Cypher statements for file 178 of 284\n",
      "Executing Cypher statements for file 179 of 284\n",
      "Executing Cypher statements for file 180 of 284\n",
      "Executing Cypher statements for file 181 of 284\n",
      "Executing Cypher statements for file 182 of 284\n",
      "Executing Cypher statements for file 183 of 284\n",
      "Executing Cypher statements for file 184 of 284\n",
      "Executing Cypher statements for file 185 of 284\n",
      "Executing Cypher statements for file 186 of 284\n",
      "Executing Cypher statements for file 187 of 284\n",
      "Executing Cypher statements for file 188 of 284\n",
      "Executing Cypher statements for file 189 of 284\n",
      "Executing Cypher statements for file 190 of 284\n",
      "Executing Cypher statements for file 191 of 284\n",
      "Executing Cypher statements for file 192 of 284\n",
      "Executing Cypher statements for file 193 of 284\n",
      "Executing Cypher statements for file 194 of 284\n",
      "Executing Cypher statements for file 195 of 284\n",
      "Executing Cypher statements for file 196 of 284\n",
      "Executing Cypher statements for file 197 of 284\n",
      "Executing Cypher statements for file 198 of 284\n",
      "Executing Cypher statements for file 199 of 284\n",
      "Executing Cypher statements for file 200 of 284\n",
      "Executing Cypher statements for file 201 of 284\n",
      "Executing Cypher statements for file 202 of 284\n",
      "Executing Cypher statements for file 203 of 284\n",
      "Executing Cypher statements for file 204 of 284\n",
      "Executing Cypher statements for file 205 of 284\n",
      "Executing Cypher statements for file 206 of 284\n",
      "Executing Cypher statements for file 207 of 284\n",
      "Executing Cypher statements for file 208 of 284\n",
      "Executing Cypher statements for file 209 of 284\n",
      "Executing Cypher statements for file 210 of 284\n",
      "Executing Cypher statements for file 211 of 284\n",
      "Executing Cypher statements for file 212 of 284\n",
      "Executing Cypher statements for file 213 of 284\n",
      "Executing Cypher statements for file 214 of 284\n",
      "Executing Cypher statements for file 215 of 284\n",
      "Executing Cypher statements for file 216 of 284\n",
      "Executing Cypher statements for file 217 of 284\n",
      "Executing Cypher statements for file 218 of 284\n",
      "Executing Cypher statements for file 219 of 284\n",
      "Executing Cypher statements for file 220 of 284\n",
      "Executing Cypher statements for file 221 of 284\n",
      "Executing Cypher statements for file 222 of 284\n",
      "Executing Cypher statements for file 223 of 284\n",
      "Executing Cypher statements for file 224 of 284\n",
      "Executing Cypher statements for file 225 of 284\n",
      "Executing Cypher statements for file 226 of 284\n",
      "Executing Cypher statements for file 227 of 284\n",
      "Executing Cypher statements for file 228 of 284\n",
      "Executing Cypher statements for file 229 of 284\n",
      "Executing Cypher statements for file 230 of 284\n",
      "Executing Cypher statements for file 231 of 284\n",
      "Executing Cypher statements for file 232 of 284\n",
      "Executing Cypher statements for file 233 of 284\n",
      "Executing Cypher statements for file 234 of 284\n",
      "Executing Cypher statements for file 235 of 284\n",
      "Executing Cypher statements for file 236 of 284\n",
      "Executing Cypher statements for file 237 of 284\n",
      "Executing Cypher statements for file 238 of 284\n",
      "Executing Cypher statements for file 239 of 284\n",
      "Executing Cypher statements for file 240 of 284\n",
      "Executing Cypher statements for file 241 of 284\n",
      "Executing Cypher statements for file 242 of 284\n",
      "Executing Cypher statements for file 243 of 284\n",
      "Executing Cypher statements for file 244 of 284\n",
      "Executing Cypher statements for file 245 of 284\n",
      "Executing Cypher statements for file 246 of 284\n",
      "Executing Cypher statements for file 247 of 284\n",
      "Executing Cypher statements for file 248 of 284\n",
      "Executing Cypher statements for file 249 of 284\n",
      "Executing Cypher statements for file 250 of 284\n",
      "Executing Cypher statements for file 251 of 284\n",
      "Executing Cypher statements for file 252 of 284\n",
      "Executing Cypher statements for file 253 of 284\n",
      "Executing Cypher statements for file 254 of 284\n",
      "Executing Cypher statements for file 255 of 284\n",
      "Executing Cypher statements for file 256 of 284\n",
      "Executing Cypher statements for file 257 of 284\n",
      "Executing Cypher statements for file 258 of 284\n",
      "Executing Cypher statements for file 259 of 284\n",
      "Executing Cypher statements for file 260 of 284\n",
      "Executing Cypher statements for file 261 of 284\n",
      "Executing Cypher statements for file 262 of 284\n",
      "Executing Cypher statements for file 263 of 284\n",
      "Executing Cypher statements for file 264 of 284\n",
      "Executing Cypher statements for file 265 of 284\n",
      "Executing Cypher statements for file 266 of 284\n",
      "Executing Cypher statements for file 267 of 284\n",
      "Executing Cypher statements for file 268 of 284\n",
      "Executing Cypher statements for file 269 of 284\n",
      "Executing Cypher statements for file 270 of 284\n",
      "Executing Cypher statements for file 271 of 284\n",
      "Executing Cypher statements for file 272 of 284\n",
      "Executing Cypher statements for file 273 of 284\n",
      "Executing Cypher statements for file 274 of 284\n",
      "Executing Cypher statements for file 275 of 284\n",
      "Executing Cypher statements for file 276 of 284\n",
      "Executing Cypher statements for file 277 of 284\n",
      "Executing Cypher statements for file 278 of 284\n",
      "Executing Cypher statements for file 279 of 284\n",
      "Executing Cypher statements for file 280 of 284\n",
      "Executing Cypher statements for file 281 of 284\n",
      "Executing Cypher statements for file 282 of 284\n",
      "Executing Cypher statements for file 283 of 284\n",
      "Executing Cypher statements for file 284 of 284\n"
     ]
    }
   ],
   "source": [
    "folders = {\n",
    "    \"people_profiles\": people_prompt_template,\n",
    "    \"project_briefs\": project_prompt_template,\n",
    "    \"slack_messages\": slack_prompt_template\n",
    "}\n",
    "\n",
    "run_pipeline(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
